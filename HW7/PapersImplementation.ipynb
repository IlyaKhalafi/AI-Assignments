{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jtNnkk2vCqhZ",
        "Fxt2TrgDdUSk",
        "KaGHrxW5dVaq"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Paper's Implementation\n",
        "\n",
        "---\n",
        "#### Course: Aritificial Intelligence\n",
        "#### Professor: Dr. Mehdi Ghatee\n",
        "#### TA: Rouhollah Ahmadian\n",
        "#### Student: Ilya Khalafi\n",
        "#### Student ID: 9913039\n",
        "#### December 2022 "
      ],
      "metadata": {
        "id": "w_lDPUbpPVe6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Table Of Contents\n",
        "- [Introduction](#intro)\n",
        "- [Dependencies](#dependency)\n",
        "- [Dataset](#dataset)\n",
        "    - [Importing Data](#import-data)\n",
        "- [Preprocessing](#preprocessing)\n",
        "    - [Encoding Labels](#encoding)\n",
        "    - [Data Split](#split)\n",
        "    - [Normalization](#normalization)\n",
        "- [Paper's Implementation](#implementation)\n",
        "    - [Step 1 - Determinig the number of features](#step1)\n",
        "    - [Step 2 - Grouping of the features](#step2)\n",
        "    - [Step 3 - Initializing particles](#step3)\n",
        "    - [Step 4 - Updating the particle positions](#step4)\n",
        "    - [Step 5 - Local search operations](#step5)\n",
        "    - [Step 6 - Calculating fitness](#step6)\n",
        "    - [Putting methods together](#final-step)\n",
        "- [Final Evaluation](#evaluation)"
      ],
      "metadata": {
        "id": "bEdOIrpBPgO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"intro\"></a>\n",
        "\n",
        "# Introduction üìö\n",
        "\n",
        "---\n",
        "\n",
        "This notebook implements and describes the following paper:\n",
        "\n",
        "**Moradi, P., & Gholampour, M. (2016). A hybrid particle swarm optimization for feature subset selection by integrating a novel local search strategy. Applied Soft Computing, 43, 117‚Äì130**\n",
        "\n",
        "Above article suggests a hybric swarm particle optimization method which has added local search to particles movement to increase the algorithm's stochasticness. The suggested algorithm as called **HPSO-LS** by the authors.\n",
        "\n",
        "It has described the algorithm's procedure during 6 steps and we will implement the algorithm step by step. Also we will use wine dataset from sklearn library to test the algorithm and compare it to model's performance without feature selection."
      ],
      "metadata": {
        "id": "ujva8HDE8BHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"dependency\"></a>\n",
        "\n",
        "#Dependencies üß∞\n",
        "\n",
        "---\n",
        "\n",
        "We need the following libraries during this article:\n",
        "\n",
        "- **numpy** : <br />\n",
        "    numpy is a commonly used library for doing scientific computation. Unlike python default pointer structure, numpy saves variables inplace and continous on RAM and also provides sophisticated methods that use parallelism to make our computations much faster.\n",
        "\n",
        "- **pandas**: <br />\n",
        "    pandas is also a common tool of data scientists. It provides many methods for data manipulation.\n",
        "\n",
        "- **matplotlib** : <br />\n",
        "    We will use matplotlib to show our charts.\n",
        "\n",
        "- **scikit-learn (sklearn)** : <br />\n",
        "    This library is a known data science library and we will import wine dataset from it and also some models and metric methods as well."
      ],
      "metadata": {
        "id": "wKbwt_oDJKZ5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1NXA_mHPNjM"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Fundamental Data Analysis Tools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Importing Common useful classes and methods from scikit-learn\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import OneHotEncoder, Normalizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Importing wine loader method from sklearn\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "# We need this to supress sklearn warning messages\n",
        "import warnings\n",
        "from sklearn.exceptions import FitFailedWarning\n",
        "warnings.filterwarnings('ignore', category=FitFailedWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"dataset\"></a>\n",
        "\n",
        "#Dataset ‚ùì\n",
        "\n",
        "---\n",
        "\n",
        "As mentioned above, we will use wine dataset from sklearn library. Every dataset in sklearn is a **dictionary** that contains features, target, labels, dataset's description and etc."
      ],
      "metadata": {
        "id": "6iDWIxA_-eaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"import-data\"></a>\n",
        "\n",
        "####Importing Data\n",
        "\n",
        "Here we load wine dataset from sklearn library.\n"
      ],
      "metadata": {
        "id": "tSQk6gG1_Ej4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wine = load_wine()\n",
        "\n",
        "# Every dataset in sklearn is a dictionary object\n",
        "# Lets observe keys of wine dictionary\n",
        "list(wine.keys())"
      ],
      "metadata": {
        "id": "Wdjtf-wGem_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "814968a8-2fa5-4d92-b43d-46a8581cb205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we should convert **'data'** into a pandas DataFrame with column names from **'feature_names'**."
      ],
      "metadata": {
        "id": "lVaiq6KY_WPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(wine['data'], columns = wine['feature_names'])\n",
        "\n",
        "# Lets take a look in the imported dataset\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "WlZuN7hhfDHf",
        "outputId": "0d00f3a1-8248-4a24-d46a-3e9ad11e5c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "\n",
              "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0        3.06                  0.28             2.29             5.64  1.04   \n",
              "1        2.76                  0.26             1.28             4.38  1.05   \n",
              "2        3.24                  0.30             2.81             5.68  1.03   \n",
              "3        3.49                  0.24             2.18             7.80  0.86   \n",
              "4        2.69                  0.39             1.82             4.32  1.04   \n",
              "\n",
              "   od280/od315_of_diluted_wines  proline  \n",
              "0                          3.92   1065.0  \n",
              "1                          3.40   1050.0  \n",
              "2                          3.17   1185.0  \n",
              "3                          3.45   1480.0  \n",
              "4                          2.93    735.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-426b5752-270f-41a0-801d-192c60037033\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-426b5752-270f-41a0-801d-192c60037033')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-426b5752-270f-41a0-801d-192c60037033 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-426b5752-270f-41a0-801d-192c60037033');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also we import class labels into a single column DataFrame named **\"target\"**. Class labels are accessible from **'target'** key of the wine dictionary."
      ],
      "metadata": {
        "id": "zNGLeDpr_gnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = pd.DataFrame(wine['target'], columns=['class'])\n",
        "\n",
        "# Lets take a look in the imported dataset\n",
        "target.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "j6PP_eFZfUqb",
        "outputId": "72f4b145-4c8b-468e-ddf2-4621f57eab0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   class\n",
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21bcdf89-791c-494f-90d2-873bf9cc706a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21bcdf89-791c-494f-90d2-873bf9cc706a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21bcdf89-791c-494f-90d2-873bf9cc706a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21bcdf89-791c-494f-90d2-873bf9cc706a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we extract label of each class from **'target_names'** of the wine dictionary."
      ],
      "metadata": {
        "id": "addXZD-j_wUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_labels = wine['target_names'].tolist()\n",
        "\n",
        "labels = {i:label for i, label in enumerate(list_of_labels)}\n",
        "\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZQBu2M1fXBE",
        "outputId": "eeb2a744-ad2a-4611-e864-359f34df673d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'class_0', 1: 'class_1', 2: 'class_2'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"preprocessing\"></a>\n",
        "\n",
        "#Preprocessing üßπ\n",
        "\n",
        "---\n",
        "\n",
        "We will implement **Encoding**, **Train-Test Split** and **Normalization** steps in this section."
      ],
      "metadata": {
        "id": "FceVnrXY-Rie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"encoding\"></a>\n",
        "\n",
        "####Encoding Labels\n",
        "\n",
        "Firstly we should encode class labels, we create a different column for each class and members of that class will have value of 1 in that column and other records will have a value of 0, this method of encoding is called **One Hot Encoding**.\n",
        "\n",
        "We use **OneHotEncoder** class from sklearn library to do this task:\n"
      ],
      "metadata": {
        "id": "xn97Ufqr-Ty1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_target = pd.DataFrame(OneHotEncoder().fit_transform(target).\n",
        "                              toarray().\n",
        "                              astype(np.int32),\n",
        "                              columns=labels.values())\n",
        "\n",
        "encoded_target.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SThd7sfXiDa_",
        "outputId": "6dc04938-ab0e-43a0-9a13-e20afeb238aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   class_0  class_1  class_2\n",
              "0        1        0        0\n",
              "1        1        0        0\n",
              "2        1        0        0\n",
              "3        1        0        0\n",
              "4        1        0        0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a85040d6-fe4d-4baa-b210-717b08857a69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class_0</th>\n",
              "      <th>class_1</th>\n",
              "      <th>class_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a85040d6-fe4d-4baa-b210-717b08857a69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a85040d6-fe4d-4baa-b210-717b08857a69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a85040d6-fe4d-4baa-b210-717b08857a69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"split\"></a>\n",
        "\n",
        "####Data Split\n",
        "\n",
        "We should take a proportion of the data for testing stage because model should not be evaluated by the same data that it is trained on. \n",
        "\n",
        "Paper mentionds that we should take 30% of the dataset for test set and the other 70% for our training set.\n",
        "\n",
        "We use **train_test_split** method from the sklearn library:\n"
      ],
      "metadata": {
        "id": "9LEpwPjYAFnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, encoded_target,\n",
        "                                                    test_size=0.3, \n",
        "                                                    shuffle=True,\n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "xgLh8TXqiiHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"normalization\"></a>\n",
        "\n",
        "####Normalization\n",
        "\n",
        "Although we have normalized our features using **Normalizer** from sklearn library in all of the previous reports, but here we have to skip this step because the paper has suggested a custom normalization function, so we will implement the suggested method in the 6th step of the implementation..."
      ],
      "metadata": {
        "id": "AO3IRy2g-Zk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"implementation\"></a>\n",
        "\n",
        "#Implementation ‚ö°\n",
        "\n",
        "---\n",
        "\n",
        "The paper has described the algorithm in 6 steps:\n",
        " - Step 1 - Determinig the number of features\n",
        " - Step 2 - Grouping of the features\n",
        " - Step 3 - Initializing particles\n",
        " - Step 4 - Updating the particle positions\n",
        " - Step 5 - Local search operations\n",
        " - Step 6 - Calculating fitness\n",
        "\n",
        " Also we add a 7th step to connect the methods and define the pipeline of the algorithm.\n",
        "\n",
        "But before the beginning, we will define to classes for our algorithm and its particles to display our road map. We will implement each method in the mentioned step."
      ],
      "metadata": {
        "id": "8KENrCocQv7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HPSOLS:\n",
        "\n",
        "    def random_sf(self, f):\n",
        "        # Step 1\n",
        "        pass\n",
        "\n",
        "    def group_features(self, features):\n",
        "        # Step 2\n",
        "        pass\n",
        "\n",
        "    def initialize_particles(num_features, k, num_particles):\n",
        "        # Step 3\n",
        "        pass\n",
        "\n",
        "    def update_particles(self):\n",
        "        # Step 4\n",
        "        pass\n",
        "\n",
        "    def local_search(self):\n",
        "        # Step 5\n",
        "        pass\n",
        "\n",
        "class Particle:\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Step 3\n",
        "        pass\n",
        "\n",
        "    def add_features(self):\n",
        "        # Step 5\n",
        "        pass\n",
        "    \n",
        "    def delete_features(self):\n",
        "        # Step 5\n",
        "        pass\n",
        "\n",
        "    def fitness(self):\n",
        "        # Step 6\n",
        "        pass"
      ],
      "metadata": {
        "id": "Rt81fkURQykj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"step1\"></a>\n",
        "\n",
        "####Step 1 - Determinig the number of features\n",
        "\n",
        "Paper has suggested a probabilistic function to choose the number of selected features (aka. sf) which assign a weight to each possible amount of selected features. Possible values of selected features are in range [x, M * f] which f is total number of original features. Also paper suggest x = 3, notice that M < 1 and by increasing M close to 1, the sf can be chosen from bigger values, so expected value of sf increases as well.\n"
      ],
      "metadata": {
        "id": "jtNnkk2vCqhZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1"
      ],
      "metadata": {
        "id": "Zg5Euio7dSj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_sf(self, f, x, eps):\n",
        "    '''\n",
        "    f = total number of original features\n",
        "    x = minimum amount of selected features\n",
        "    eps = epsilon defined by the paper which describes\n",
        "          maximum proportion of the features that can be selected\n",
        "\n",
        "    output : total number of features to select by the algorithm\n",
        "    '''\n",
        "\n",
        "    lsf_arr = []\n",
        "\n",
        "    for sf in range(x, int(eps * f)):\n",
        "        lsf = (f - sf) / sum(list(range(1, f-sf+1)))\n",
        "        lsf_arr.append(lsf)\n",
        "\n",
        "    total_sum = sum(lsf_arr)\n",
        "\n",
        "    lsf_arr = [sf / total_sum for sf in lsf_arr]\n",
        "\n",
        "    return np.random.choice(list(range(x, int(eps * f))), p=lsf_arr)\n",
        "\n",
        "# Adding method to HPSOLS class\n",
        "HPSOLS.random_sf = random_sf"
      ],
      "metadata": {
        "id": "7uXZvsj1M82N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"step2\"></a>\n",
        "\n",
        "####Step 2 - Grouping of the features\n",
        "\n",
        "In this step we will divide features into similar and dissimilar features. Firstly we calculate correlation among pairs of features using peasorm method and then for each features we calculate average of value of its correlation with other features. Then we sort features based on this average correlation and first half of features will make the set of dissimliar features (aka. D) and the other half will make the set of similar features (aka. S).\n"
      ],
      "metadata": {
        "id": "Fxt2TrgDdUSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def group_features(self, features):\n",
        "    '''\n",
        "    features : dataframe of features to group\n",
        "\n",
        "    output : list D and S including dissimilar and similar features\n",
        "    '''\n",
        "    \n",
        "    df = pd.DataFrame(features)\n",
        "\n",
        "    correlations = df.corr(method = 'pearson')\n",
        "\n",
        "    # We minus 1 each element of sum because i != j in cor_i calculation\n",
        "    # and correlation of each feature to itself is 1.0\n",
        "    cors = (correlations.abs().sum() - 1) / (len(features.columns) - 1)\n",
        "\n",
        "    cors = cors.tolist()\n",
        "\n",
        "    ordered = [x for _,x in sorted(zip(cors, list(range(0, len(features.columns)))))]\n",
        "\n",
        "    D = ordered[0 : len(ordered) // 2] # group of dissimilar features\n",
        "    S = ordered[len(ordered) // 2 :] # group of similar features\n",
        "\n",
        "    return (S, D)\n",
        "\n",
        "# Adding method to HPSOLS class\n",
        "HPSOLS.group_features = group_features"
      ],
      "metadata": {
        "id": "ssXgxhQ5P-dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"step3\"></a>\n",
        "\n",
        "####Step 3 - Initializing particles\n",
        "\n",
        "In this step we will define particle to build our swarm model. Paper defines each particles with 2 vectors, one for the position of the particle and another for the velocity, just like the ordinary PSO system. But position of each particles is a binary vector with the size of total features, so each features is selected by the particle if its element in the vector is equal to 1 and other its element will be 0. Also velocity vector has the same size as position vector and its element represent probability of each feature being selected.\n",
        "\n",
        "For the sake of clean code, we will define particles as instances of Particle class and also pass the features and target of the training to its constructor, we will use features and target of the training set later in methods of the Particle class.\n",
        "\n",
        "Also each particles should keep its best selected features and the value corresponding to the selected features. Step 4 of the paper has described an update formula with specific r1 and r2 values for each particles so we will keep these values for each particle as well."
      ],
      "metadata": {
        "id": "KaGHrxW5dVaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_particles(self, num_features, k, num_particles):\n",
        "    '''\n",
        "    num_features = total number of  original features, it will \n",
        "        represent size of binary vector for each particle\n",
        "\n",
        "    k = number of selected features from step 1\n",
        "\n",
        "    num_particles = total number of particles to initialize\n",
        "    '''\n",
        "    velocities = np.random.rand(num_particles, num_features)\n",
        "    particles = []\n",
        "\n",
        "    for i in range(num_particles):\n",
        "        # Initializing particles position\n",
        "        position = np.zeros(num_features)\n",
        "        position[:k]  = 1\n",
        "        np.random.shuffle(position)\n",
        "\n",
        "        # Creating particle's object\n",
        "        new_particle = Particle(position, velocities[i], self.features, self.target)\n",
        "        particles.append(new_particle)\n",
        "    \n",
        "    return particles\n",
        "\n",
        "# Adding method to HPSOLS class\n",
        "HPSOLS.initialize_particles = initialize_particles"
      ],
      "metadata": {
        "id": "YmEJ5SfzoeYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __particle_init__(self, selected_features, velocity, features, target):\n",
        "    '''\n",
        "    This method will be set as constructor of the Particle class\n",
        "    '''\n",
        "    self.selected_features = selected_features\n",
        "    self.velocity = velocity\n",
        "    self.features = features\n",
        "    self.target = target\n",
        "    self.r1 = np.random.random()\n",
        "    self.r2 = np.random.random()\n",
        "    self.best_x = self.selected_features.copy()\n",
        "    self.best_x_value = self.fitness()\n",
        "\n",
        "# Adding method to Particle class\n",
        "Particle.__init__ = __particle_init__"
      ],
      "metadata": {
        "id": "v6VBiLG2aSu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"step4\"></a>\n",
        "\n",
        "####Step 4 - Updating the particle positions\n",
        "\n",
        "This step mostly consists of formulas. Firstly we will update each particle's velocity and then we calculate sigmoid function for each element of the velocity vector and this value shows the probability of selection for its corresponding feature, then we compare this probability with a random value in range [0, 1], if the probability was bigger that the random value we select the feature and set its value in position vector equal to 1 and 0 otherwise."
      ],
      "metadata": {
        "id": "5UhD2sArdXeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_particles(self):\n",
        "    # Step 4\n",
        "\n",
        "    # Algorithm Parameters\n",
        "    # Values are suggested by paper itself\n",
        "    v_min = -4\n",
        "    v_max = 4\n",
        "    c1 = c2 = 2\n",
        "\n",
        "    # best x_g is stored in instance of HPSOLS \n",
        "    best_x_g = self.best_x\n",
        "\n",
        "    for particle in self.particles:\n",
        "        # Each particle has its own r1, r2\n",
        "        # absed on the formula of the Step 4\n",
        "        r1 = particle.r1\n",
        "        r2 = particle.r2\n",
        "\n",
        "        # Also each particle has a presonal x_best\n",
        "        best_x_i = particle.best_x\n",
        "\n",
        "        # Updating velocity\n",
        "        particle.velocity = particle.velocity + c1 * r1 * (best_x_i - particle.velocity) * np.linalg.norm(particle.velocity, 2) + c2 * r2 * (best_x_g - particle.selected_features)\n",
        "        particle.velocity = np.maximum(particle.velocity, v_min)\n",
        "        particle.velocity = np.minimum(particle.velocity, v_max)\n",
        "\n",
        "        # probs define probability of each feature being selected\n",
        "        # It is calculated using the sigmoid function\n",
        "        probs = 1 / ( 1 + np.exp(-particle.velocity) )\n",
        "\n",
        "        # Now we compare probability of selection for each feature\n",
        "        # with a random value to decide whether to choose it or not\n",
        "        particle.selected_features = (probs > np.random.rand()).astype(np.int32)\n",
        "\n",
        "# Adding method to Particle class\n",
        "HPSOLS.update_particles = update_particles"
      ],
      "metadata": {
        "id": "Ec9q4yih2sLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"step5\"></a>\n",
        "\n",
        "####Step 5 - Local search operations\n",
        "\n",
        "This step utilizes PSO with local search and it is the critical and key step of the paper. After updating each particles position (aka selected features) not we apply local search to adjust amount of similar and dissimilar features selected by the particle. Paper introduces parameters alpha in range [0, 1] which represents proportion of selected features that should be from similar features. We add or delete similar and dissimilar features to adjust this proportion using local search. Paper has not specified the local search so we will use hill climbing in this section."
      ],
      "metadata": {
        "id": "GppwxqK2svqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def local_search(self):\n",
        "    # Step 5\n",
        "    for particle in self.particles:\n",
        "        # notice that features exists in D and S in ascending order according\n",
        "        # to their correlation, so they will be sorted in X_d and X_s as well\n",
        "        \n",
        "        X_d = [feature for feature in self.D if particle.selected_features[feature] == 1]\n",
        "        X_s = [feature for feature in self.S if particle.selected_features[feature] == 1]\n",
        "\n",
        "        n_s = int(self.alpha * self.sf)\n",
        "        n_d = int((1 - self.alpha) * self.sf)\n",
        "\n",
        "        if len(X_d) < n_d:\n",
        "            new_features = [feature for feature in self.D if not feature in X_d]\n",
        "            particle.add_features(new_features, n_d - len(X_d))\n",
        "\n",
        "        elif len(X_d) > n_d:\n",
        "            old_features = X_d\n",
        "            particle.delete_features(old_features, len(X_d) - n_d)\n",
        "\n",
        "        if len(X_s) < n_s:\n",
        "            new_features = [feature for feature in self.S if not feature in X_s]\n",
        "            particle.add_features(new_features, n_s - len(X_s))\n",
        "\n",
        "        elif len(X_s) > n_s:\n",
        "            old_features = X_s\n",
        "            particle.delete_features(old_features, len(X_s) - n_s)\n",
        "    \n",
        "        fitness = particle.fitness()\n",
        "\n",
        "        # Updating particle's best personal position\n",
        "        if fitness > particle.best_x_value:\n",
        "            particle.best_x_value = fitness\n",
        "            particle.best_x = particle.selected_features.copy()\n",
        "\n",
        "        # Updating global best position\n",
        "        if fitness > self.best_x_value:\n",
        "            self.best_x_value = fitness\n",
        "            print(f'**Updated global best value, new value: {fitness}')\n",
        "            self.best_x = particle.selected_features.copy()\n",
        "\n",
        "# Adding method to HPSOLS class\n",
        "HPSOLS.local_search = local_search"
      ],
      "metadata": {
        "id": "UPrV3A-gsxGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use hill climbing for local search\n",
        "def add_features(self, new_features, total_add):\n",
        "    '''\n",
        "    new_features : a list containing index of features\n",
        "                   that can be added\n",
        "    total_add : number of features to add from new_features\n",
        "\n",
        "    output : None\n",
        "\n",
        "    Applys local search to add 'total_add' number of features\n",
        "    from list of new_features\n",
        "    '''\n",
        "    # Step 5\n",
        "    while total_add > 0 and len(new_features) != 0:\n",
        "        best_val = self.fitness()\n",
        "        target_feature = -1\n",
        "        # Finding best feature to add\n",
        "        for feature in new_features:\n",
        "            self.selected_features[feature] = 1\n",
        "            val = self.fitness()\n",
        "            self.selected_features[feature] = 0\n",
        "            if val > best_val:\n",
        "                target_feature = feature\n",
        "\n",
        "        # If position can't be improved (local maximum)\n",
        "        # Then we should return\n",
        "        if target_feature == -1:\n",
        "            return\n",
        "\n",
        "        # Selecting found feature\n",
        "        self.selected_features[target_feature] = 1\n",
        "        new_features.remove(target_feature)\n",
        "        total_add -= 1\n",
        "\n",
        "def delete_features(self, old_features, total_delete):\n",
        "    '''\n",
        "    old_features : a list containing index of features\n",
        "                   that can be deleted\n",
        "    total_delete : number of features to delete from old_features\n",
        "\n",
        "    output : None\n",
        "\n",
        "    Applys local search to delete 'total_delete' number of features\n",
        "    from list of old_features\n",
        "    '''\n",
        "    # Step 5\n",
        "    while total_delete > 0 and len(old_features) != 0:\n",
        "        best_val = self.fitness()\n",
        "        target_feature = -1\n",
        "        # Finding best feature to delete\n",
        "        for feature in old_features:\n",
        "            self.selected_features[feature] = 0\n",
        "            val = self.fitness()\n",
        "            self.selected_features[feature] = 1\n",
        "            if val > best_val:\n",
        "                target_feature = feature\n",
        "\n",
        "        # If position can't be improved (local maximum)\n",
        "        # Then we should return\n",
        "        if target_feature == -1:\n",
        "            return\n",
        "\n",
        "        # Unselecting found feature\n",
        "        self.selected_features[target_feature] = 0\n",
        "        old_features.remove(target_feature)\n",
        "        total_delete -= 1\n",
        "\n",
        "# Adding method to Particle class\n",
        "Particle.add_features = add_features\n",
        "Particle.delete_features = delete_features"
      ],
      "metadata": {
        "id": "GQEVz-IS6tcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"step6\"></a>\n",
        "\n",
        "####Step 6 - Calculating fitness\n",
        "\n",
        "Last step of the paper has described the fitness method of particles. Fitness method provides a measure for selected features by the particle. Paper uses KNeighbor model to evaluate the model and also uses K Fold Validation with k = 10.\n",
        "\n",
        "Also this step suggests a custom normalization function and we will implement it as well and inject it into instance of HPSOLS class, so to compare model's performance we will use the normalizer that exists inside the HPSOLS instance. "
      ],
      "metadata": {
        "id": "B6q24qra6vWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomNormalizer:\n",
        "\n",
        "    def fit_transform(self, features):\n",
        "        self.x_max = features.max()\n",
        "        self.x_min = features.min()\n",
        "\n",
        "        return self.transform(features)\n",
        "\n",
        "    def transform(self, features):\n",
        "        # Paper mentioned that each features\n",
        "        # must be in range [-1, 1]\n",
        "        l = -1\n",
        "        u = 1\n",
        "\n",
        "        normal_features = l + (u-l) * (features - self.x_max) / (self.x_max - self.x_min)\n",
        "\n",
        "        return normal_features"
      ],
      "metadata": {
        "id": "WUvP0VhlBsTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fitness(self):\n",
        "    # Step 6\n",
        "    kneighbors = KNeighborsClassifier()\n",
        "\n",
        "    return cross_val_score(kneighbors,\n",
        "                           self.features.loc[:,self.selected_features.astype(bool)],\n",
        "                           self.target,\n",
        "                           cv = 10, # 10 is suggested by the paper\n",
        "                           n_jobs = -1,\n",
        "                           error_score=0).mean()\n",
        "    \n",
        "\n",
        "# Adding method to Particle class\n",
        "Particle.fitness = fitness"
      ],
      "metadata": {
        "id": "tFR2H1o06wKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"final-step\"></a>\n",
        "\n",
        "####Putting methods together\n",
        "\n",
        "Now we have implemented all step and we have to put pieces of the puzzle together. Here we implement constructor method for HPSOLS class to initialize properties of the algorithm and then we define a method named **optimize** to repeat steps of the algorithm."
      ],
      "metadata": {
        "id": "OzMtEE6-bZl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def __init__(self, features, target, x=3, eps=0.8, num_particles=50, alpha=0.65):\n",
        "    '''\n",
        "    features : dataframe of features that will algorithm work on\n",
        "    target : label columns for features\n",
        "    x : minimum number of selecting features\n",
        "    eps : maximum proportion of selecting features\n",
        "    num_particles : number of particles in swarm\n",
        "    alpha : proportion of selecting features to be similar\n",
        "\n",
        "    output : this constructor method of HPSOLS class and makes\n",
        "             an instance of the HPSOLS class\n",
        "    '''\n",
        "    self.normalizer = CustomNormalizer()\n",
        "    features = self.normalizer.fit_transform(features)\n",
        "    self.features = features\n",
        "    self.target = target\n",
        "    self.alpha = alpha\n",
        "    # Step 1\n",
        "    self.sf = self.random_sf(len(features.columns), x=x, eps=eps)\n",
        "    # Step 2\n",
        "    self.S, self.D = self.group_features(features)\n",
        "    # Step 3\n",
        "    self.particles = self.initialize_particles(len(features.columns), self.sf, num_particles)\n",
        "    \n",
        "    # Calculating global best score among all particles\n",
        "    scores = [particle.best_x_value for particle in self.particles]\n",
        "    positions = [particle.best_x.tolist() for particle in self.particles]\n",
        "    best_pair = max( zip(scores, positions) )\n",
        "    self.best_x_value = best_pair[0]\n",
        "    self.best_x = np.array(best_pair[1])\n",
        "    # best_x of hposls instance keeps global best score\n",
        "    # but best_x of each particles just keeps its personal best\n",
        "\n",
        "# Adding method to HPSOLS class\n",
        "HPSOLS.__init__ = __init__"
      ],
      "metadata": {
        "id": "-_SO-McjU9vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize(self, iterations=100, log_period=5):\n",
        "    '''\n",
        "    iterations : number of iterations to repeat algorithm procedure\n",
        "    log_period : number of iteration to skip between displaying best score\n",
        "\n",
        "    output : a numpy array which represent global best x\n",
        "    '''\n",
        "    for i in range(iterations):\n",
        "        # Step 4\n",
        "        self.update_particles()\n",
        "        # Step 5\n",
        "        self.local_search()\n",
        "\n",
        "        if i % log_period == 0:\n",
        "            print(f'Best value iteration {i+1}: {self.best_x_value}')\n",
        "\n",
        "    return self.best_x\n",
        "\n",
        "# Adding method to HPSOLS class\n",
        "HPSOLS.optimize = optimize"
      ],
      "metadata": {
        "id": "4R_U8BLibg96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"evaluation\"></a>\n",
        "\n",
        "####Final Evaluation\n",
        "\n",
        "Finally we start our algorithm! We will use KNeighbor Classifier to display perfomance of selected features by HPSO-LS and also we make KNeighbor Classifier to work on original features to show the difference of HPSO-LS."
      ],
      "metadata": {
        "id": "0fKyDZTUsTns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kneighbor = KNeighborsClassifier()\n",
        "\n",
        "hpso = HPSOLS(X_train, y_train, x=3, eps=0.5, alpha=0.65, num_particles=5)\n",
        "selected_features = hpso.optimize(iterations=20, log_period=1)\n",
        "\n",
        "hpso_features = hpso.features.loc[:,selected_features.astype(bool)]\n",
        "\n",
        "X_test_normal = hpso.normalizer.transform(X_test)\n",
        "X_test_normal_selected = X_test_normal.loc[:, selected_features.astype(bool)]\n",
        "\n",
        "print('-' * 30)\n",
        "\n",
        "kneighbor.fit(hpso.features, hpso.target)\n",
        "print(f'Total Features: {len(hpso.features.columns)}')\n",
        "print(f'Accuracy: {kneighbor.score(X_test_normal, y_test)}')\n",
        "\n",
        "print('-' * 30)\n",
        "kneighbor.fit(hpso_features, hpso.target)\n",
        "print(f'Selected Features: {len(hpso_features.columns)}')\n",
        "print(f'Accuracy with HPSO-LS: {kneighbor.score(X_test_normal_selected, y_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6FP00k2Dc3l",
        "outputId": "b7685e86-bc71-4a3c-c6dd-86e8ce6b34ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Updated global best value, new value: 0.9692307692307693\n",
            "Best value iteration 1: 0.9692307692307693\n",
            "**Updated global best value, new value: 0.9839743589743589\n",
            "Best value iteration 2: 0.9839743589743589\n",
            "Best value iteration 3: 0.9839743589743589\n",
            "Best value iteration 4: 0.9839743589743589\n",
            "Best value iteration 5: 0.9839743589743589\n",
            "Best value iteration 6: 0.9839743589743589\n",
            "Best value iteration 7: 0.9839743589743589\n",
            "Best value iteration 8: 0.9839743589743589\n",
            "Best value iteration 9: 0.9839743589743589\n",
            "Best value iteration 10: 0.9839743589743589\n",
            "Best value iteration 11: 0.9839743589743589\n",
            "Best value iteration 12: 0.9839743589743589\n",
            "Best value iteration 13: 0.9839743589743589\n",
            "Best value iteration 14: 0.9839743589743589\n",
            "Best value iteration 15: 0.9839743589743589\n",
            "Best value iteration 16: 0.9839743589743589\n",
            "Best value iteration 17: 0.9839743589743589\n",
            "Best value iteration 18: 0.9839743589743589\n",
            "Best value iteration 19: 0.9839743589743589\n",
            "Best value iteration 20: 0.9839743589743589\n",
            "------------------------------\n",
            "Total Features: 13\n",
            "Accuracy: 0.9444444444444444\n",
            "------------------------------\n",
            "Selected Features: 10\n",
            "Accuracy with HPSO-LS: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We set number of particles to a small value because otherwise it would converge much faster and considering that wine dataset has only 13 features, algorithm would fine its optimal results in the first 2 iterations and that wouldn't be fun! So I sat number of particle to a small value to decrease the speed of convergence so we observer algorithms performance better!"
      ],
      "metadata": {
        "id": "3VkSXhy50rj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we see that HPSO-LS algorithm improved our model's accuracy by 6% percent and interestingly selected features helped the KNeighbor Classifier to make a perfect classification! notice that wine dataset only has 13 features so it is not a surprise that feature selection doesn't have big effect on it, but for bigger datasets with more features it is possible to see much more effect by HPSO-LS algorithm!"
      ],
      "metadata": {
        "id": "a-SpziFo_sSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is available in the link below: üôÇ \n",
        "\n",
        "https://colab.research.google.com/drive/1VqZt46HVowBmiwnacSIZKr9KCttH0kte?usp=sharing\n",
        "\n",
        "Feel free to change HPSO-LS parameters to analyze the results..."
      ],
      "metadata": {
        "id": "_PR16fHw0u-F"
      }
    }
  ]
}